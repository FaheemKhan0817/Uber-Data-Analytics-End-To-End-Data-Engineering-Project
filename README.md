# Uber Data Analytics: End-to-End Data Engineering Project ğŸš–ğŸ’»

Welcome to my **Uber Data Analytics** project, an end-to-end data engineering pipeline that transforms raw Uber trip data into actionable insights using modern cloud and MLOps tools. This project showcases my expertise in **data pipelines**, **cloud infrastructure**, and **data visualization**, built with Google Cloud Platform (GCP), Mage AI, Docker, BigQuery, and Looker Studio.

ğŸ“º **Watch the Project Walkthrough**: [YouTube Video](https://youtu.be/bwKvjfUDKac)  
ğŸ“Š **Explore the Dashboard**: [Looker Studio Dashboard](https://lookerstudio.google.com/reporting/3c1c4e41-c3d5-4bca-ac0c-af37e905b9d7)  
ğŸŒ **Connect with Me**: [LinkedIn](https://linkedin.com/in/faheemkhanml)  
ğŸ“‚ **Source Code**: [GitHub Repository](https://github.com/FaheemKhan0817/Uber-Data-Analytics-End-To-End-Data-Engineering-Project.git)

---

## ğŸš€ Project Overview

This project builds a scalable data pipeline to process Uber trip data (e.g., `trips.csv`) and deliver interactive visualizations. The pipeline:
- **Ingests** raw data from a GCP Storage Bucket.
- **Processes** data using a Mage AI pipeline on a GCP VM instance.
- **Stores** transformed data in BigQuery.
- **Visualizes** insights via a Looker Studio dashboard, showcasing metrics like trip volume, fares, and geographic trends.

### Workflow Diagram
```
[Start]
  â†“
[GCP Bucket (gs://uber-data-2025)]
  â†“
[VM Instance (uber-data-instance)]
  â†“
[Install Docker]
  â†“
[Run Mage AI Container]
  â†“
[Mage AI Pipeline]
  â”œâ”€â”€â”€>[Data Loader Block]â”€â”€â”€>[Load Data (trips.csv)]
  â”‚     â†“
  â”œâ”€â”€â”€>[Transformer Block]â”€â”€â”€>[Transform Data (clean, convert types)]
  â”‚     â†“
  â””â”€â”€â”€>[Data Exporter Block]â”€â”€â”€>[Export to BigQuery]
        â†“
[BigQuery (uber_data_dataset.trips_table)]
  â†“
[Looker Studio]
  â†“
[Uber Dashboard Visualization]
  â†“
[End]
```

---

## ğŸ› ï¸ Tools & Technologies

- **Google Cloud Platform (GCP)**:
  - **Cloud Storage**: Stores raw data (e.g., `gs://uber-data-2025/trips.csv`).
  - **Compute Engine**: Hosts the VM instance (`uber-data-instance`).
  - **BigQuery**: Stores transformed data (`uber_data_dataset.trips_table`).
- **Docker**: Containerizes Mage AI for pipeline orchestration.
- **Mage AI**: Builds and manages the ETL pipeline (Extract, Transform, Load).
- **Looker Studio**: Creates interactive dashboards for data visualization.
- **Python**: Powers data processing in Mage AI (e.g., Pandas for transformations).
- **SQL**: Queries data in BigQuery.

---

## ğŸ“‚ Project Structure

```
Uber-Data-Analytics-End-To-End-Data-Engineering-Project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uber_data.csv               # Sample Uber trip data
â”œâ”€â”€ mage_pipeline/
â”‚   â”œâ”€â”€ data_loader.py         # Loads data from GCP Bucket
â”‚   â”œâ”€â”€ transformer.py         # Cleans and transforms data
â”‚   â””â”€â”€ data_exporter.py       # Exports to BigQuery
â”œâ”€â”€ docker-compose.yml         # Docker configuration for Mage AI
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â””â”€â”€ .gitignore                 # Git ignore file
```

---

## âš™ï¸ Setup Instructions

Follow these steps to replicate the project locally or on GCP.

### Prerequisites
- Google Cloud account with billing enabled.
- Docker installed on your machine or VM.
- Python 3.8+ installed.
- GCP SDK (`gcloud`) configured.
- Access to BigQuery and Looker Studio.

### Step-by-Step Setup
1. **Clone the Repository**
   ```bash
   git clone https://github.com/FaheemKhan0817/Uber-Data-Analytics-End-To-End-Data-Engineering-Project.git
   cd Uber-Data-Analytics-End-To-End-Data-Engineering-Project
   ```

2. **Set Up GCP**
   - Create a GCP project (e.g., `uber-data-project`).
   - Enable APIs: Cloud Storage, Compute Engine, BigQuery.
   - Create a Storage Bucket: `gs://uber-data-2025`.
   - Upload `trips.csv` to the bucket.
   - Create a VM instance (e.g., `uber-data-instance`, n2-standard-4, Ubuntu 20.04).

3. **Install Docker on VM**
   ```bash
   sudo apt-get update
   sudo apt-get install -y docker.io
   sudo systemctl start docker
   sudo systemctl enable docker
   ```

4. **Run Mage AI Container**
   ```bash
   docker run -p 6789:6789 -v $(pwd)/mage_pipeline:/home/src mageai/mageai
   ```
   - Access Mage AI at `http://<VM_EXTERNAL_IP>:6789`.

5. **Configure Mage AI Pipeline**
   - Create a new pipeline in Mage AI.
   - Add blocks:
     - **Data Loader**: Load `uber_data.csv` from `gs://uber-data-2025`.
     - **Transformer**: Clean data (e.g., remove nulls, convert dates).
     - **Data Exporter**: Export to BigQuery (`uber_data_dataset.table`).
   - Authenticate GCP in Mage AI (use service account key).

6. **Set Up BigQuery**
   - Create a dataset: `uber_data_dataset`.
   - Let Mage AI create the table (`table`) during export.

7. **Create Looker Studio Dashboard**
   - Connect Looker Studio to BigQuery (`uber_data_dataset.table`).
   - Build visualizations (e.g., bar charts for trip volume, maps for pickup locations).
   - View the dashboard: [Link](https://lookerstudio.google.com/reporting/3c1c4e41-c3d5-4bca-ac0c-af37e905b9d7).

8. **Run the Pipeline**
   - Execute the pipeline in Mage AI.
   - Verify data in BigQuery and visualizations in Looker Studio.

---

## ğŸ“Š Dashboard Highlights

The Looker Studio dashboard provides insights into Uber trip data, including:
- **Trip Volume**: Daily/monthly trip counts.
- **Average Fares**: Trends over time.
- **Geographic Heatmaps**: Pickup and drop-off locations.
- **Trip Duration**: Distribution of trip lengths.

ğŸ”— **View Dashboard**: [Looker Studio](https://lookerstudio.google.com/reporting/3c1c4e41-c3d5-4bca-ac0c-af37e905b9d7)

---

## ğŸ¥ Video Explanation

For a detailed walkthrough of the project, including setup and pipeline execution, check out my YouTube video:

ğŸ”— **Watch Now**: [YouTube Video](https://youtu.be/bwKvjfUDKac)

---

## ğŸŒŸ Why This Project?

This project demonstrates my skills in:
- **MLOps**: Orchestrating pipelines with Mage AI and Docker.
- **Cloud Engineering**: Leveraging GCP for storage, compute, and analytics.
- **Data Engineering**: Building robust ETL pipelines.
- **Data Visualization**: Creating impactful dashboards with Looker Studio.

---

## ğŸ‘¨â€ğŸ’» About Me

Hi, Iâ€™m **Faheem Khan**, a passionate **Machine Learning Engineer** and **Data Engineer** specializing in MLOps, cloud platforms, and data pipelines. Iâ€™m actively seeking opportunities to build scalable AI solutions.

- **LinkedIn**: [Faheem Khan](https://linkedin.com/in/faheemkhanml)
- **GitHub**: [FaheemKhan0817](https://github.com/FaheemKhan0817)
- **Portfolio**: [Faheem Khan](https://www.datascienceportfol.io/Faheem_Khan)

---

## ğŸ™Œ Acknowledgments

- **Darshil Parmar** YouTube tutorials.
- **Mage AI** and **GCP** communities for excellent documentation.

---

## ğŸ“¬ Get in Touch

Interested in collaborating or hiring? Reach out via [LinkedIn](https://linkedin.com/in/faheemkhanml) or explore the code on [GitHub](https://github.com/FaheemKhan0817/Uber-Data-Analytics-End-To-End-Data-Engineering-Project.git). Letâ€™s build something amazing together! ğŸš€

---